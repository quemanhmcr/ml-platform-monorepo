# =============================================================================
# Argo Workflow Template for ML Training Pipeline
# =============================================================================
apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: ml-training-pipeline
spec:
  entrypoint: training-pipeline
  serviceAccountName: ml-training-sa
  
  # Workflow arguments
  arguments:
    parameters:
      - name: data-version
        value: "latest"
      - name: model-version
        value: ""
      - name: hyperparameters
        value: '{"learning_rate": 0.001, "batch_size": 32}'
  
  # Main pipeline
  templates:
    - name: training-pipeline
      steps:
        - - name: data-ingestion
            template: data-ingestion
            arguments:
              parameters:
                - name: data-version
                  value: "{{workflow.parameters.data-version}}"
        
        - - name: data-processing
            template: data-processing
            arguments:
              parameters:
                - name: data-version
                  value: "{{workflow.parameters.data-version}}"
        
        - - name: data-eda
            template: data-eda
            arguments:
              parameters:
                - name: data-version
                  value: "{{workflow.parameters.data-version}}"
        
        - - name: train-model
            template: train-model
            arguments:
              parameters:
                - name: data-version
                  value: "{{workflow.parameters.data-version}}"
                - name: model-version
                  value: "{{workflow.parameters.model-version}}"
                - name: hyperparameters
                  value: "{{workflow.parameters.hyperparameters}}"
    
    # Data Ingestion Step
    - name: data-ingestion
      container:
        image: # Will be overridden by overlays
        command: [python, -m, src.main]
        env:
          - name: COMPONENT_NAME
            value: "data_ingestion"
          - name: S3_DATA_LAKE_BUCKET
            valueFrom:
              configMapKeyRef:
                name: ml-training-config
                key: S3_DATA_LAKE_BUCKET
        resources:
          requests:
            cpu: "500m"
            memory: "1Gi"
          limits:
            cpu: "2000m"
            memory: "2Gi"
    
    # Data Processing Step
    - name: data-processing
      container:
        image: # Will be overridden by overlays
        command: [python, -m, src.main]
        env:
          - name: COMPONENT_NAME
            value: "data_processing"
          - name: S3_DATA_LAKE_BUCKET
            valueFrom:
              configMapKeyRef:
                name: ml-training-config
                key: S3_DATA_LAKE_BUCKET
        resources:
          requests:
            cpu: "500m"
            memory: "1Gi"
          limits:
            cpu: "2000m"
            memory: "2Gi"
    
    # Data EDA Step
    - name: data-eda
      container:
        image: # Will be overridden by overlays
        command: [python, -m, src.main]
        env:
          - name: COMPONENT_NAME
            value: "data_eda"
          - name: S3_DATA_LAKE_BUCKET
            valueFrom:
              configMapKeyRef:
                name: ml-training-config
                key: S3_DATA_LAKE_BUCKET
        resources:
          requests:
            cpu: "500m"
            memory: "1Gi"
          limits:
            cpu: "2000m"
            memory: "2Gi"
    
    # Train Model Step
    - name: train-model
      container:
        image: # Will be overridden by overlays
        command: [python, -m, src.main]
        env:
          - name: COMPONENT_NAME
            value: "train"
          - name: S3_DATA_LAKE_BUCKET
            valueFrom:
              configMapKeyRef:
                name: ml-training-config
                key: S3_DATA_LAKE_BUCKET
          - name: HYPERPARAMETERS
            value: "{{inputs.parameters.hyperparameters}}"
        resources:
          requests:
            cpu: "1000m"
            memory: "4Gi"
          limits:
            cpu: "4000m"
            memory: "8Gi"
        volumeMounts:
          - name: model-storage
            mountPath: /models

