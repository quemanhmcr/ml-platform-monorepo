# üîß Pod Optimization Analysis - Gi·∫£i Ph√≥ng Ch·ªó Cho ArgoCD Deployments

**Ng√†y ph√¢n t√≠ch:** 2025-11-07  
**M·ª•c ti√™u:** T·ªëi ∆∞u system pods ƒë·ªÉ gi·∫£i ph√≥ng pod slots cho application deployments

---

## üìä Hi·ªán Tr·∫°ng Pod Distribution

### Pod Count per Node

| Node | System Pods | ArgoCD Pods | Total | Status |
|------|-------------|-------------|-------|--------|
| ip-10-0-1-82 | 4 (aws-node, kube-proxy, ebs-csi-node, coredns) | 1 (applicationset-controller) | **5** | ‚ö†Ô∏è **V∆∞·ª£t gi·ªõi h·∫°n** |
| ip-10-0-1-122 | 3 (aws-node, kube-proxy, ebs-csi-node) | 1 (applicationset-controller) | 4 | ‚úÖ At limit |
| ip-10-0-2-117 | 3 (aws-node, kube-proxy, ebs-csi-node) | 1 (repo-server) | 4 | ‚úÖ At limit |
| ip-10-0-2-231 | 3 (aws-node, kube-proxy, ebs-csi-node) | 1 (application-controller) | 4 | ‚úÖ At limit |
| ip-10-0-3-13 | 3 (aws-node, kube-proxy, ebs-csi-node) | 1 (redis) | 4 | ‚úÖ At limit |
| ip-10-0-3-87 | 3 (aws-node, kube-proxy, ebs-csi-node) | 1 (server) | 4 | ‚úÖ At limit |

**T·ªïng k·∫øt:**
- **Total System Pods:** 19 pods
- **Total ArgoCD Pods:** 5 pods
- **Total Running:** 24 pods
- **Pending Application Pods:** 4 pods (kh√¥ng th·ªÉ schedule)

### Chi Ti·∫øt System Pods

#### DaemonSets (Required tr√™n m·ªói node)

| Component | Pods | Containers/Pod | CPU Request | Memory Request | Status |
|-----------|------|----------------|-------------|----------------|--------|
| **aws-node** | 6 | 2 | 25m x 2 = 50m | - | ‚úÖ **Required** |
| **kube-proxy** | 6 | 1 | 100m | - | ‚úÖ **Required** |
| **ebs-csi-node** | 6 | 3 | 10m x 3 = 30m | 40Mi x 3 = 120Mi | ‚ö†Ô∏è **C√≥ th·ªÉ t·ªëi ∆∞u** |

#### Deployments

| Component | Replicas | CPU Request | Memory Request | Status |
|-----------|----------|-------------|----------------|--------|
| **coredns** | 1 | 100m | 70Mi | ‚úÖ ƒê√£ scale down |
| **ebs-csi-controller** | 0 | - | - | ‚úÖ ƒê√£ scale down |

---

## ‚ö†Ô∏è V·∫•n ƒê·ªÅ Ph√°t Hi·ªán

### 1. Node ip-10-0-1-82 V∆∞·ª£t Gi·ªõi H·∫°n Pods

**V·∫•n ƒë·ªÅ:**
- Node n√†y c√≥ **5 pods** trong khi t3.micro ch·ªâ h·ªó tr·ª£ t·ªëi ƒëa **4 pods/node**
- Pods tr√™n node n√†y:
  1. aws-node-7fmjh (daemonset)
  2. kube-proxy-r9kn7 (daemonset)
  3. ebs-csi-node-sp7rk (daemonset)
  4. coredns-58d7b66669-xllnv (deployment)
  5. argocd-applicationset-controller (deployment)

**Nguy√™n nh√¢n:**
- Coredns pod ƒë∆∞·ª£c schedule v√†o node n√†y
- ArgoCD applicationset-controller c≈©ng ƒë∆∞·ª£c schedule v√†o node n√†y
- C·∫£ hai ƒë·ªÅu l√† deployment pods (c√≥ th·ªÉ di chuy·ªÉn)

### 2. ebs-csi-node Chi·∫øm Nhi·ªÅu Resources

**V·∫•n ƒë·ªÅ:**
- M·ªói ebs-csi-node pod c√≥ **3 containers** (driver, registrar, liveness-probe)
- Chi·∫øm **30m CPU** v√† **120Mi memory** m·ªói node
- T·ªïng c·ªông: **180m CPU** v√† **720Mi memory** tr√™n 6 nodes

**Ph√¢n t√≠ch:**
- ebs-csi-node l√† daemonset ‚Üí ch·∫°y tr√™n t·∫•t c·∫£ nodes
- C·∫ßn thi·∫øt n·∫øu s·ª≠ d·ª•ng EBS volumes
- Nh∆∞ng c√≥ th·ªÉ t·ªëi ∆∞u b·∫±ng c√°ch ch·ªâ ch·∫°y tr√™n m·ªôt s·ªë nodes nh·∫•t ƒë·ªãnh

---

## üí° Gi·∫£i Ph√°p ƒê·ªÅ Xu·∫•t

### Priority 1: Di Chuy·ªÉn Coredns Pod (Immediate)

**V·∫•n ƒë·ªÅ:** Coredns pod ƒëang ·ªü node ip-10-0-1-82 (ƒë√£ c√≥ 5 pods)

**Gi·∫£i ph√°p:** S·ª≠ d·ª•ng node affinity ƒë·ªÉ di chuy·ªÉn coredns sang node kh√°c

```bash
# Ki·ªÉm tra node c√≥ √≠t pods nh·∫•t
kubectl get pods --all-namespaces -o wide | findstr "ip-10-0-1-122"

# Patch coredns deployment v·ªõi node affinity
kubectl patch deployment coredns -n kube-system -p '{"spec":{"template":{"spec":{"affinity":{"nodeAffinity":{"preferredDuringSchedulingIgnoredDuringExecution":[{"preference":{"matchExpressions":[{"key":"kubernetes.io/hostname","operator":"NotIn","values":["ip-10-0-1-82.ap-southeast-2.compute.internal"]}]},"weight":100}]}}}}}}'
```

**Ho·∫∑c scale down v√† scale up l·∫°i:**
```bash
kubectl scale deployment coredns -n kube-system --replicas=0
kubectl scale deployment coredns -n kube-system --replicas=1
```

**Impact:** Gi·∫£i ph√≥ng 1 pod slot tr√™n node ip-10-0-1-82

---

### Priority 2: T·ªëi ∆Øu ebs-csi-node DaemonSet (High Impact)

**Option A: Gi·∫£m s·ªë l∆∞·ª£ng ebs-csi-node pods b·∫±ng node selector**

**Ph√¢n t√≠ch:**
- EBS CSI driver c·∫ßn ch·∫°y tr√™n nodes c√≥ EBS volumes
- V·ªõi t3.micro v√† kh√¥ng c√≥ persistent volumes, c√≥ th·ªÉ ch·ªâ c·∫ßn 2-3 pods thay v√¨ 6

**Gi·∫£i ph√°p:** S·ª≠ d·ª•ng node selector ƒë·ªÉ ch·ªâ ch·∫°y tr√™n m·ªôt s·ªë nodes

```bash
# Patch ebs-csi-node daemonset v·ªõi node selector
kubectl patch daemonset ebs-csi-node -n kube-system -p '{"spec":{"template":{"spec":{"nodeSelector":{"ebs-csi":"enabled"}}}}}'

# Label ch·ªâ 2-3 nodes ƒë·ªÉ ch·∫°y ebs-csi-node
kubectl label nodes ip-10-0-1-122.ap-southeast-2.compute.internal ebs-csi=enabled
kubectl label nodes ip-10-0-2-117.ap-southeast-2.compute.internal ebs-csi=enabled
kubectl label nodes ip-10-0-3-13.ap-southeast-2.compute.internal ebs-csi=enabled

# Unlabel c√°c nodes kh√°c
kubectl label nodes ip-10-0-1-82.ap-southeast-2.compute.internal ebs-csi-
kubectl label nodes ip-10-0-2-231.ap-southeast-2.compute.internal ebs-csi-
kubectl label nodes ip-10-0-3-87.ap-southeast-2.compute.internal ebs-csi-
```

**Impact:** 
- Gi·∫£m t·ª´ 6 pods ‚Üí 3 pods
- Gi·∫£i ph√≥ng **3 pod slots** tr√™n 3 nodes
- Gi·∫£i ph√≥ng **180m CPU** v√† **360Mi memory**

**L∆∞u √Ω:** 
- Ch·ªâ l√†m n·∫øu kh√¥ng s·ª≠ d·ª•ng EBS volumes tr√™n t·∫•t c·∫£ nodes
- N·∫øu c·∫ßn EBS volumes, ph·∫£i ƒë·∫£m b·∫£o nodes c√≥ label `ebs-csi=enabled`

---

**Option B: Gi·∫£m s·ªë containers trong ebs-csi-node (Kh√¥ng khuy·∫øn ngh·ªã)**

- Ph·ª©c t·∫°p v√† c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn functionality
- Kh√¥ng n√™n l√†m tr·ª´ khi th·ª±c s·ª± c·∫ßn thi·∫øt

---

### Priority 3: T·ªëi ∆Øu ArgoCD Pod Distribution

**Hi·ªán t·∫°i:** ArgoCD pods ƒë∆∞·ª£c ph√¢n b·ªï ƒë·ªÅu tr√™n c√°c nodes

**ƒê·ªÅ xu·∫•t:** S·ª≠ d·ª•ng pod anti-affinity ƒë·ªÉ tr√°nh t·∫≠p trung tr√™n m·ªôt node

```yaml
# Th√™m v√†o ArgoCD Helm values
controller:
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values:
              - argocd-application-controller
          topologyKey: kubernetes.io/hostname
```

**Impact:** ƒê·∫£m b·∫£o ArgoCD pods kh√¥ng t·∫≠p trung tr√™n m·ªôt node

---

### Priority 4: Scale Down Staging Deployments

**Hi·ªán t·∫°i:** Staging deployments ƒëang Pending

**Gi·∫£i ph√°p:** X√≥a staging deployments ƒë·ªÉ gi·∫£i ph√≥ng resources

```bash
# X√≥a staging deployments (ƒë√£ disabled trong ApplicationSet)
kubectl delete deployment ml-recommendation-inference -n ml-inference-staging
```

**Impact:** Gi·∫£i ph√≥ng 2 pending pods (kh√¥ng chi·∫øm slot nh∆∞ng ƒëang ch·ªù)

---

## üìã Action Plan

### Immediate Actions (L√†m ngay)

1. ‚úÖ **Di chuy·ªÉn coredns pod**
   ```bash
   kubectl scale deployment coredns -n kube-system --replicas=0
   kubectl scale deployment coredns -n kube-system --replicas=1
   ```
   **Expected:** Gi·∫£i ph√≥ng 1 pod slot tr√™n node ip-10-0-1-82

2. ‚úÖ **X√≥a staging deployments**
   ```bash
   kubectl delete deployment ml-recommendation-inference -n ml-inference-staging
   ```
   **Expected:** X√≥a 2 pending pods

### Short-term Actions (Trong tu·∫ßn n√†y)

3. ‚úÖ **T·ªëi ∆∞u ebs-csi-node (Option A)**
   - Label 3 nodes v·ªõi `ebs-csi=enabled`
   - Patch daemonset v·ªõi node selector
   - **Expected:** Gi·∫£i ph√≥ng 3 pod slots

4. ‚úÖ **Verify v√† test**
   - Ki·ªÉm tra application pods c√≥ th·ªÉ schedule kh√¥ng
   - Monitor node resources

### Long-term Actions (Trong th√°ng n√†y)

5. ‚úÖ **Upgrade node instance type**
   - T·ª´ t3.micro ‚Üí t3.small ho·∫∑c t3.medium
   - **Expected:** TƒÉng pod capacity t·ª´ 4 ‚Üí 11 ho·∫∑c 17 pods/node

---

## üéØ Expected Results

### Sau khi √°p d·ª•ng Immediate + Short-term Actions:

**Pod Distribution:**
- **ebs-csi-node:** 6 pods ‚Üí 3 pods (-3 pods)
- **coredns:** Di chuy·ªÉn sang node kh√°c (gi·∫£i ph√≥ng 1 slot)
- **Staging:** X√≥a 2 pending pods

**Total Pod Slots Freed:** ~4-5 pod slots

**Nodes c√≥ th·ªÉ schedule th√™m pods:**
- ip-10-0-1-82: 5 pods ‚Üí 4 pods (sau khi di chuy·ªÉn coredns)
- ip-10-0-1-122: 4 pods ‚Üí 3 pods (sau khi gi·∫£m ebs-csi-node)
- ip-10-0-2-117: 4 pods ‚Üí 3 pods (sau khi gi·∫£m ebs-csi-node)
- ip-10-0-3-13: 4 pods ‚Üí 3 pods (sau khi gi·∫£m ebs-csi-node)

**K·∫øt qu·∫£:** C√≥ th·ªÉ schedule √≠t nh·∫•t **1 production inference pod**

---

## ‚ö†Ô∏è L∆∞u √ù Quan Tr·ªçng

### ebs-csi-node Optimization

**Tr∆∞·ªõc khi gi·∫£m ebs-csi-node pods:**

1. **Ki·ªÉm tra EBS volumes:**
   ```bash
   kubectl get pv
   kubectl get pvc --all-namespaces
   ```

2. **Ki·ªÉm tra workloads s·ª≠ d·ª•ng EBS:**
   ```bash
   kubectl get pods --all-namespaces -o json | ConvertFrom-Json | 
     ForEach-Object { $_.items | Where-Object { $_.spec.volumes -match "persistentVolumeClaim" } }
   ```

3. **N·∫øu c√≥ EBS volumes:**
   - ƒê·∫£m b·∫£o nodes c√≥ label `ebs-csi=enabled` c√≥ th·ªÉ access volumes
   - Ho·∫∑c kh√¥ng gi·∫£m ebs-csi-node pods

### Coredns Relocation

**Sau khi di chuy·ªÉn coredns:**
- Verify DNS resolution v·∫´n ho·∫°t ƒë·ªông
- Monitor coredns metrics

---

## üîß Commands Reference

### Check Current Pod Distribution
```bash
# Pods per node
kubectl get pods --all-namespaces -o wide | Group-Object { $_.NODE } | 
  Select-Object Name, Count

# Detailed view
kubectl get pods --all-namespaces -o custom-columns=NAME:.metadata.name,NODE:.spec.nodeName,NAMESPACE:.metadata.namespace
```

### Optimize ebs-csi-node
```bash
# Label nodes
kubectl label nodes <node-name> ebs-csi=enabled

# Patch daemonset
kubectl patch daemonset ebs-csi-node -n kube-system -p '{"spec":{"template":{"spec":{"nodeSelector":{"ebs-csi":"enabled"}}}}}'

# Verify
kubectl get pods -n kube-system -l app=ebs-csi-node -o wide
```

### Relocate Coredns
```bash
# Scale down and up
kubectl scale deployment coredns -n kube-system --replicas=0
kubectl scale deployment coredns -n kube-system --replicas=1

# Check new location
kubectl get pods -n kube-system -l k8s-app=kube-dns -o wide
```

---

## üìä Monitoring

### After Optimization

```bash
# Check pod distribution
kubectl get pods --all-namespaces -o wide | Group-Object { $_.NODE }

# Check pending pods
kubectl get pods --all-namespaces --field-selector=status.phase=Pending

# Check node resources
kubectl describe nodes | Select-String -Pattern "Allocated resources" -Context 5
```

---

**Last Updated:** 2025-11-07  
**Status:** ‚ö†Ô∏è C·∫ßn th·ª±c hi·ªán optimization ƒë·ªÉ gi·∫£i ph√≥ng pod slots

